{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TSYWBXtSulvj",
   "metadata": {
    "id": "TSYWBXtSulvj"
   },
   "outputs": [],
   "source": [
    "# pip install pyDOE \n",
    "# 如果没有pyDOE 请安装一下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5806Iyrygs",
   "metadata": {
    "id": "de5806Iyrygs"
   },
   "source": [
    "# 7-4 记录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ujmvUqlrtrtK",
   "metadata": {
    "id": "ujmvUqlrtrtK"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "PRleQlMxsPkv",
   "metadata": {
    "id": "PRleQlMxsPkv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "import datetime, os\n",
    "#hide tf logs \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'} \n",
    "#0 (default) shows all, 1 to filter out INFO logs, 2 to additionally filter out WARNING logs, and 3 to additionally filter out ERROR logs\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import seaborn as sns \n",
    "import codecs, json\n",
    "\n",
    "# generates same random numbers each time\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RIr2UC39r_eJ",
   "metadata": {
    "id": "RIr2UC39r_eJ"
   },
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yleHhp5pr8Hx",
   "metadata": {
    "id": "yleHhp5pr8Hx"
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('Data/burgers_shock_mu_01_pi.mat')  \t# Load data from file\n",
    "x = data['x']                                   # 256 points between -1 and 1 [256x1]\n",
    "t = data['t']                                   # 100 time points between 0 and 1 [100x1] \n",
    "usol = data['usol']                             # solution of 256x100 grid points\n",
    "\n",
    "X, T = np.meshgrid(x,t)                         # makes 2 arrays X and T such that u(X[i],T[j])=usol[i][j] are a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GWE5LTvgsz_c",
   "metadata": {
    "id": "GWE5LTvgsz_c"
   },
   "source": [
    "## *Test Data*\n",
    "\n",
    "We prepare the test data to compare against the solution produced by the PINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imd-bmrbsuFA",
   "metadata": {
    "id": "imd-bmrbsuFA"
   },
   "outputs": [],
   "source": [
    "''' X_u_test = [X[i],T[i]] [25600,2] for interpolation'''\n",
    "X_u_test = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "# Domain bounds\n",
    "lb = X_u_test[0]  # [-1. 0.]\n",
    "ub = X_u_test[-1] # [1.  0.99]\n",
    "\n",
    "'''\n",
    "   Fortran Style ('F') flatten,stacked column wise!\n",
    "   u = [c1 \n",
    "        c2\n",
    "        .\n",
    "        .\n",
    "        cn]\n",
    "\n",
    "   u =  [25600x1] \n",
    "'''\n",
    "u = usol.flatten('F')[:,None] \n",
    "X_u_test = tf.constant(X_u_test,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flY0BZGes9He",
   "metadata": {
    "id": "flY0BZGes9He"
   },
   "source": [
    "## *Training Data*\n",
    "\n",
    "The boundary conditions serve as the test data for the PINN and the collocation points are generated using **Latin Hypercube Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hPe9lqzAtBHf",
   "metadata": {
    "id": "hPe9lqzAtBHf"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f):\n",
    "\n",
    "    '''Boundary Conditions'''\n",
    "\n",
    "    #Initial Condition -1 =< x =<1 and t = 0  \n",
    "    leftedge_x = np.hstack((X[0,:][:,None], T[0,:][:,None])) #L1\n",
    "    leftedge_u = usol[:,0][:,None]\n",
    "\n",
    "    #Boundary Condition x = -1 and 0 =< t =<1\n",
    "    bottomedge_x = np.hstack((X[:,0][:,None], T[:,0][:,None])) #L2\n",
    "    bottomedge_u = usol[-1,:][:,None]\n",
    "\n",
    "    #Boundary Condition x = 1 and 0 =< t =<1\n",
    "    topedge_x = np.hstack((X[:,-1][:,None], T[:,0][:,None])) #L3\n",
    "    topedge_u = usol[0,:][:,None]\n",
    "\n",
    "    all_X_u_train = np.vstack([leftedge_x, bottomedge_x, topedge_x]) # X_u_train [456,2] (456 = 256(L1)+100(L2)+100(L3))\n",
    "    all_u_train = np.vstack([leftedge_u, bottomedge_u, topedge_u])   #corresponding u [456x1]\n",
    "\n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(all_X_u_train.shape[0], N_u, replace=False) \n",
    "\n",
    "    X_u_train = all_X_u_train[idx, :] #choose indices from  set 'idx' (x,t)\n",
    "    u_train = all_u_train[idx,:]      #choose corresponding u\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    X_f_train = lb + (ub-lb)*lhs(2,N_f) \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "\n",
    "    return X_f_train, X_u_train, u_train \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k52AslOQ0sw7",
   "metadata": {
    "id": "k52AslOQ0sw7"
   },
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9FwQc60w2_",
   "metadata": {
    "id": "fc9FwQc60w2_"
   },
   "outputs": [],
   "source": [
    "def solutionplot(u_pred,X_u_train,u_train):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "\n",
    "    gs0 = gridspec.GridSpec(1, 2)\n",
    "    gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "    ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "    h = ax.imshow(u_pred, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[T.min(), T.max(), X.min(), X.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(h, cax=cax)\n",
    "    \n",
    "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
    "\n",
    "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
    "\n",
    "    ax.set_xlabel('$t$')\n",
    "    ax.set_ylabel('$x$')\n",
    "    ax.legend(frameon=False, loc = 'best')\n",
    "    ax.set_title('$u(x,t)$', fontsize = 10)\n",
    "    \n",
    "    ''' \n",
    "    Slices of the solution at points t = 0.25, t = 0.50 and t = 0.75\n",
    "    '''\n",
    "    \n",
    "    ####### Row 1: u(t,x) slices ##################\n",
    "    gs1 = gridspec.GridSpec(1, 3)\n",
    "    gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "    ax = plt.subplot(gs1[0, 0])\n",
    "    ax.plot(x,usol.T[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')    \n",
    "    ax.set_title('$t = 0.25s$', fontsize = 10)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "    ax = plt.subplot(gs1[0, 1])\n",
    "    ax.plot(x,usol.T[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "    ax.set_title('$t = 0.50s$', fontsize = 10)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "    ax = plt.subplot(gs1[0, 2])\n",
    "    ax.plot(x,usol.T[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])    \n",
    "    ax.set_title('$t = 0.75s$', fontsize = 10)\n",
    "    \n",
    "    #plt.savefig('./Results/Burgers.png',dpi = 500)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tm6iCb7CtHzW",
   "metadata": {
    "id": "tm6iCb7CtHzW"
   },
   "source": [
    "## MyPinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KPYQTH6MtJ6D",
   "metadata": {
    "id": "KPYQTH6MtJ6D"
   },
   "outputs": [],
   "source": [
    "def createModel(layer,Model):\n",
    "    if len(layer) < 2:\n",
    "        print(\"层数小于2！, 无法构建神经网络\")\n",
    "        return \n",
    "    model = Model(name = \"PINN\")\n",
    "    model.add(keras.Input(shape=(layer[0],),dtype=tf.float64))\n",
    "    for i in range(1,len(layer)-1):\n",
    "        model.add(layers.Dense(layer[i],dtype=tf.float64, activation=\"tanh\", name=\"layer{}\".format(i)))\n",
    "    model.add(layers.Dense(layer[-1], dtype=tf.float64,name=\"outputs\"))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9BUcvFcIuAsv",
   "metadata": {
    "id": "9BUcvFcIuAsv"
   },
   "outputs": [],
   "source": [
    "class MyPinn(keras.Sequential): ## 正在编写\n",
    "    def __init__(self,name = None):\n",
    "        \n",
    "        super(MyPinn, self).__init__(name=name)\n",
    "        self.nu = tf.constant(0.01/np.pi,dtype=tf.float64)\n",
    "    \n",
    "    @tf.function\n",
    "    def test_gradient(self,X_f_train):\n",
    "        x = X_f_train[:,0]\n",
    "        t = X_f_train[:,1]\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch([x,t])\n",
    "            X = tf.stack([x,t],axis=-1)\n",
    "            u = self(X)\n",
    "        u_x = tape.gradient(u,x)\n",
    "        tf.print(u_x)\n",
    "    \n",
    "    @tf.function\n",
    "    def loss_U(self,X_u_train,u_train):\n",
    "        u_pred = self(X_u_train)\n",
    "        loss_u = tf.reduce_mean(tf.square(u_train - u_pred))\n",
    "        return loss_u\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def loss_PDE(self,X_f_train):\n",
    "        x = X_f_train[:,0]\n",
    "        t = X_f_train[:,1]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch([x,t])\n",
    "            X = tf.stack([x,t],axis=-1)\n",
    "            u = self(X)  \n",
    "            u_x = tape.gradient(u,x)         \n",
    "            \n",
    "        u_t = tape.gradient(u, t)     \n",
    "        u_xx = tape.gradient(u_x, x)\n",
    "        \n",
    "        del tape\n",
    "        \n",
    "        f = u_t + (self(X_f_train))*(u_x) - (self.nu)*u_xx\n",
    "\n",
    "        loss_f = tf.reduce_mean(tf.square(f))\n",
    "\n",
    "        return loss_f\n",
    "    \n",
    "    @tf.function\n",
    "    def loss_Total(self,X_u_train,u_train,X_f_train):\n",
    "        loss_u = self.loss_U(X_u_train,u_train)\n",
    "        loss_f = self.loss_PDE(X_f_train)\n",
    "        \n",
    "        loss_total = loss_u + loss_f\n",
    "        \n",
    "        return loss_total\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self,X_u_train,u_train,X_f_train):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            loss_total = self.loss_Total(X_u_train,u_train,X_f_train)\n",
    "                   \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss_total, trainable_vars)\n",
    "        \n",
    "        del tape\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        return loss_total\n",
    "    \n",
    "    @tf.function\n",
    "    def train_model(self, X_u_train,u_train,X_f_train, epochs=100):\n",
    "        for epoch in tf.range(1,epochs+1):\n",
    "            loss_total = self.train_step(X_u_train,u_train,X_f_train)\n",
    "            if epoch % 10 == 0:                \n",
    "                tf.print(\n",
    "                    \"Training loss (for per 10 epoches) at epoch \",epoch,\":\",loss_total\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Efis1vL5yH53",
   "metadata": {
    "id": "Efis1vL5yH53"
   },
   "outputs": [],
   "source": [
    "def function_factory(model, loss, X_u_train,u_train,X_f_train):\n",
    "    \"\"\"A factory to create a function required by tfp.optimizer.lbfgs_minimize.\n",
    "    Args:\n",
    "        model [in]: an instance of `tf.keras.Model` or its subclasses.\n",
    "        loss [in]: a loss function in model\n",
    "    Returns:\n",
    "        A function that has a signature of:\n",
    "            loss_value, gradients = f(model_parameters).\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain the shapes of all trainable parameters in the model\n",
    "    shapes = tf.shape_n(model.trainable_variables)\n",
    "    n_tensors = len(shapes)\n",
    "\n",
    "    # we'll use tf.dynamic_stitch and tf.dynamic_partition later, so we need to\n",
    "    # prepare required information first\n",
    "    count = 0\n",
    "    idx = [] # stitch indices\n",
    "    part = [] # partition indices\n",
    "\n",
    "    for i, shape in enumerate(shapes):\n",
    "        n = np.product(shape)\n",
    "        idx.append(tf.reshape(tf.range(count, count+n, dtype=tf.int32), shape))\n",
    "        part.extend([i]*n)\n",
    "        count += n\n",
    "\n",
    "    part = tf.constant(part)\n",
    "\n",
    "    @tf.function\n",
    "    def assign_new_model_parameters(params_1d):\n",
    "        \"\"\"A function updating the model's parameters with a 1D tf.Tensor.\n",
    "        Args:\n",
    "            params_1d [in]: a 1D tf.Tensor representing the model's trainable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        params = tf.dynamic_partition(params_1d, part, n_tensors)\n",
    "        for i, (shape, param) in enumerate(zip(shapes, params)):\n",
    "            model.trainable_variables[i].assign(tf.reshape(param, shape))\n",
    "\n",
    "    # now create a function that will be returned by this factory\n",
    "    @tf.function\n",
    "    def f(params_1d):\n",
    "        \"\"\"A function that can be used by tfp.optimizer.lbfgs_minimize.\n",
    "        This function is created by function_factory.\n",
    "        Args:\n",
    "           params_1d [in]: a 1D tf.Tensor.\n",
    "        Returns:\n",
    "            A scalar loss and the gradients w.r.t. the `params_1d`.\n",
    "        \"\"\"\n",
    "\n",
    "        # use GradientTape so that we can calculate the gradient of loss w.r.t. parameters\n",
    "        with tf.GradientTape() as tape:\n",
    "            # update the parameters in the model\n",
    "            assign_new_model_parameters(params_1d)\n",
    "            # calculate the loss\n",
    "            loss_value = loss(X_u_train,u_train,X_f_train)\n",
    "\n",
    "        # calculate gradients and convert to 1D tf.Tensor\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        grads = tf.dynamic_stitch(idx, grads)\n",
    "\n",
    "        # print out iteration & loss\n",
    "        f.iter.assign_add(1)\n",
    "        tf.print(\"Iter:\", f.iter, \"loss:\", loss_value)\n",
    "\n",
    "        # store loss value so we can retrieve later\n",
    "        tf.py_function(f.history.append, inp=[loss_value], Tout=[])\n",
    "\n",
    "        return loss_value, grads\n",
    "\n",
    "    # store these information as members so we can use them outside the scope\n",
    "    f.iter = tf.Variable(0)\n",
    "    f.idx = idx\n",
    "    f.part = part\n",
    "    f.shapes = shapes\n",
    "    f.assign_new_model_parameters = assign_new_model_parameters\n",
    "    f.history = []\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IU2edVj4uOW7",
   "metadata": {
    "id": "IU2edVj4uOW7"
   },
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8jl7R_x6uFKt",
   "metadata": {
    "id": "8jl7R_x6uFKt"
   },
   "outputs": [],
   "source": [
    "N_u = 100 #Total number of data points for 'u'\n",
    "N_f = 1000 #Total number of collocation points \n",
    "\n",
    "# Training data\n",
    "X_f_train, X_u_train, u_train = trainingdata(N_u,N_f)\n",
    "X_f_train = tf.constant(X_f_train,dtype=tf.float64)\n",
    "X_u_train = tf.constant(X_u_train,dtype=tf.float64)\n",
    "u_train = tf.constant(u_train,dtype=tf.float64)\n",
    "\n",
    "layer = [2,20,20,20,20,20,20,20,20,1] #8 hidden layer\n",
    "\n",
    "\n",
    "m1= createModel(layer,MyPinn)\n",
    "m1.compile(keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d874603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for per 10 epoches) at epoch  10 : 0.10355588820140703\n",
      "Training loss (for per 10 epoches) at epoch  20 : 0.10062672993883215\n",
      "Training loss (for per 10 epoches) at epoch  30 : 0.099471302945212531\n",
      "Training loss (for per 10 epoches) at epoch  40 : 0.099076789608032248\n",
      "Training loss (for per 10 epoches) at epoch  50 : 0.0990805789119594\n",
      "Training loss (for per 10 epoches) at epoch  60 : 0.09908209075445408\n",
      "Training loss (for per 10 epoches) at epoch  70 : 0.099070963202972151\n",
      "Training loss (for per 10 epoches) at epoch  80 : 0.099064847516392163\n",
      "Training loss (for per 10 epoches) at epoch  90 : 0.099062221604510212\n",
      "Training loss (for per 10 epoches) at epoch  100 : 0.0990609503813042\n",
      "Training loss (for per 10 epoches) at epoch  110 : 0.099060127174689788\n",
      "Training loss (for per 10 epoches) at epoch  120 : 0.099059549798398178\n",
      "Training loss (for per 10 epoches) at epoch  130 : 0.099059088021484762\n",
      "Training loss (for per 10 epoches) at epoch  140 : 0.099058647938994146\n",
      "Training loss (for per 10 epoches) at epoch  150 : 0.099058226428719157\n",
      "Training loss (for per 10 epoches) at epoch  160 : 0.099057831867462684\n",
      "Training loss (for per 10 epoches) at epoch  170 : 0.09905745348805331\n",
      "Training loss (for per 10 epoches) at epoch  180 : 0.09905709144864451\n",
      "Training loss (for per 10 epoches) at epoch  190 : 0.099056742924115065\n",
      "Training loss (for per 10 epoches) at epoch  200 : 0.099056406512111866\n"
     ]
    }
   ],
   "source": [
    "m1.train_model(X_u_train,u_train,X_f_train,epochs=200) ## Adam优化阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "JduuINUxwTNo",
   "metadata": {
    "id": "JduuINUxwTNo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1 loss: 0.099105181991899091\n",
      "Iter: 2 loss: 0.09914635983608186\n",
      "Iter: 3 loss: 0.099105175833695949\n",
      "Iter: 4 loss: 0.099105171560245883\n",
      "Iter: 5 loss: 0.09910517089814\n",
      "Iter: 6 loss: 0.0991051679344358\n",
      "Iter: 7 loss: 0.099105159323534919\n",
      "Iter: 8 loss: 0.09910513555146773\n",
      "Iter: 9 loss: 0.099105272864149122\n",
      "Iter: 10 loss: 0.099105128755839891\n",
      "Iter: 11 loss: 0.099105089304167934\n",
      "Iter: 12 loss: 0.099105162577423786\n",
      "Iter: 13 loss: 0.0991050724670976\n",
      "Iter: 14 loss: 0.099105026443919331\n",
      "Iter: 15 loss: 0.099104867470401661\n",
      "Iter: 16 loss: 0.099104674858708608\n",
      "Iter: 17 loss: 0.099104627289561917\n",
      "Iter: 18 loss: 0.099103964519511659\n",
      "Iter: 19 loss: 0.099103583119813862\n",
      "Iter: 20 loss: 0.099103304434345535\n",
      "Iter: 21 loss: 0.099102691829728876\n",
      "Iter: 22 loss: 0.09911204406922948\n",
      "Iter: 23 loss: 0.099102691712953148\n",
      "Iter: 24 loss: 0.099102094475647884\n",
      "Iter: 25 loss: 0.099101842446501373\n",
      "Iter: 26 loss: 0.099101526363264886\n",
      "Iter: 27 loss: 0.099100706836413435\n",
      "Iter: 28 loss: 0.099101536372051116\n",
      "Iter: 29 loss: 0.099100244904902934\n",
      "Iter: 30 loss: 0.099099580519066074\n",
      "Iter: 31 loss: 0.099100868142372012\n",
      "Iter: 32 loss: 0.099099308494242352\n",
      "Iter: 33 loss: 0.099098791857157711\n",
      "Iter: 34 loss: 0.099099405737655216\n",
      "Iter: 35 loss: 0.099098518306032016\n",
      "Iter: 36 loss: 0.099102702245776053\n",
      "Iter: 37 loss: 0.0990984972762914\n",
      "Iter: 38 loss: 0.099098467059976852\n",
      "Iter: 39 loss: 0.099098610201215548\n",
      "Iter: 40 loss: 0.0990984616108497\n",
      "Iter: 41 loss: 0.099098391038783151\n",
      "Iter: 42 loss: 0.09909828737821845\n",
      "Iter: 43 loss: 0.099098284687906685\n",
      "Iter: 44 loss: 0.099098054586844841\n",
      "Iter: 45 loss: 0.099099262299878949\n",
      "Iter: 46 loss: 0.099098017854001116\n",
      "Iter: 47 loss: 0.099097941769922412\n",
      "Iter: 48 loss: 0.09909775508590557\n",
      "Iter: 49 loss: 0.099099656893272853\n",
      "Iter: 50 loss: 0.099097732405105693\n",
      "Iter: 51 loss: 0.099097490134582841\n",
      "Iter: 52 loss: 0.099097486365334345\n",
      "Iter: 53 loss: 0.0990972409597857\n",
      "Iter: 54 loss: 0.099098209319769454\n",
      "Iter: 55 loss: 0.099097182221031976\n",
      "Iter: 56 loss: 0.0990969149700276\n",
      "Iter: 57 loss: 0.099097237975087279\n",
      "Iter: 58 loss: 0.099096775251803215\n",
      "Iter: 59 loss: 0.099096551815440442\n",
      "Iter: 60 loss: 0.0990970198976619\n",
      "Iter: 61 loss: 0.0990964636036499\n",
      "Iter: 62 loss: 0.099096113514374654\n",
      "Iter: 63 loss: 0.099096182606793037\n",
      "Iter: 64 loss: 0.09909585048900979\n",
      "Iter: 65 loss: 0.099095470481268239\n",
      "Iter: 66 loss: 0.099094810717017964\n",
      "Iter: 67 loss: 0.099094810585567975\n",
      "Iter: 68 loss: 0.0990944035860328\n",
      "Iter: 69 loss: 0.099097827983506276\n",
      "Iter: 70 loss: 0.099094373119973253\n",
      "Iter: 71 loss: 0.09909423277175157\n",
      "Iter: 72 loss: 0.0990942323515078\n",
      "Iter: 73 loss: 0.0990941789131632\n",
      "Iter: 74 loss: 0.099094260476980375\n",
      "Iter: 75 loss: 0.0990941536313344\n",
      "Iter: 76 loss: 0.099093950531118427\n",
      "Iter: 77 loss: 0.099095611452571633\n",
      "Iter: 78 loss: 0.099093937386091055\n",
      "Iter: 79 loss: 0.099093696476401386\n",
      "Iter: 80 loss: 0.099093423547488221\n",
      "Iter: 81 loss: 0.099093388157320272\n",
      "Iter: 82 loss: 0.099093097931832269\n",
      "Iter: 83 loss: 0.099093047603851764\n",
      "Iter: 84 loss: 0.099092849535837718\n",
      "Iter: 85 loss: 0.099092460574104382\n",
      "Iter: 86 loss: 0.09909299093249356\n",
      "Iter: 87 loss: 0.099092265099941554\n",
      "Iter: 88 loss: 0.099091983178013723\n",
      "Iter: 89 loss: 0.099092199675290871\n",
      "Iter: 90 loss: 0.099091811926142609\n",
      "Iter: 91 loss: 0.099091572277320461\n",
      "Iter: 92 loss: 0.099091322251523867\n",
      "Iter: 93 loss: 0.099091278622480725\n",
      "Iter: 94 loss: 0.099091043050039268\n",
      "Iter: 95 loss: 0.099090625918468178\n",
      "Iter: 96 loss: 0.099100712737587721\n",
      "Iter: 97 loss: 0.099090625915049635\n",
      "Iter: 98 loss: 0.099090358999198547\n",
      "Iter: 99 loss: 0.099092630722650121\n",
      "Iter: 100 loss: 0.099090343710908677\n",
      "Iter: 101 loss: 0.099090228510271772\n",
      "Iter: 102 loss: 0.099089959933538974\n",
      "Iter: 103 loss: 0.099093309077895986\n",
      "Iter: 104 loss: 0.099089938854114754\n",
      "Iter: 105 loss: 0.099090079010057119\n",
      "Iter: 106 loss: 0.099089720272171639\n",
      "Iter: 107 loss: 0.0990895827535801\n",
      "Iter: 108 loss: 0.099090273745565935\n",
      "Iter: 109 loss: 0.099089560310924044\n",
      "Iter: 110 loss: 0.099089432589286458\n",
      "Iter: 111 loss: 0.099091784355853474\n",
      "Iter: 112 loss: 0.099089432588481643\n",
      "Iter: 113 loss: 0.099089283288314456\n",
      "Iter: 114 loss: 0.09908960158442405\n",
      "Iter: 115 loss: 0.0990892250496167\n",
      "Iter: 116 loss: 0.099089140066789788\n",
      "Iter: 117 loss: 0.099089067632750716\n",
      "Iter: 118 loss: 0.09908902576966859\n",
      "Iter: 119 loss: 0.099088996849144378\n",
      "Iter: 120 loss: 0.099088981679617619\n",
      "Iter: 121 loss: 0.099088929100013642\n",
      "Iter: 122 loss: 0.099088854809781246\n",
      "Iter: 123 loss: 0.099088852096093152\n",
      "Iter: 124 loss: 0.09908868378647688\n",
      "Iter: 125 loss: 0.0990888963543711\n",
      "Iter: 126 loss: 0.099088597709052387\n",
      "Iter: 127 loss: 0.0990883892332608\n",
      "Iter: 128 loss: 0.099089910409815574\n",
      "Iter: 129 loss: 0.099088372271223538\n",
      "Iter: 130 loss: 0.099088232502236973\n",
      "Iter: 131 loss: 0.09908804966156444\n",
      "Iter: 132 loss: 0.0990880381537062\n",
      "Iter: 133 loss: 0.099087849149371743\n",
      "Iter: 134 loss: 0.099088382609074113\n",
      "Iter: 135 loss: 0.099087788268192423\n",
      "Iter: 136 loss: 0.09908788724139049\n",
      "Iter: 137 loss: 0.099087685714011109\n",
      "Iter: 138 loss: 0.099087601442779616\n",
      "Iter: 139 loss: 0.0990873661643288\n",
      "Iter: 140 loss: 0.099088631376701111\n",
      "Iter: 141 loss: 0.099087293477634078\n",
      "Iter: 142 loss: 0.099086970865689766\n",
      "Iter: 143 loss: 0.09908700017840584\n",
      "Iter: 144 loss: 0.099086724695260239\n",
      "Iter: 145 loss: 0.099086573736232142\n",
      "Iter: 146 loss: 0.099086561964107284\n",
      "Iter: 147 loss: 0.099086592224373424\n",
      "Iter: 148 loss: 0.099086504865209174\n",
      "Iter: 149 loss: 0.099086470440305455\n",
      "Iter: 150 loss: 0.099086690217375262\n",
      "Iter: 151 loss: 0.099086466718845828\n",
      "Iter: 152 loss: 0.099086437368009067\n",
      "Iter: 153 loss: 0.099086352959608964\n",
      "Iter: 154 loss: 0.099086722548749978\n",
      "Iter: 155 loss: 0.099086321075085\n",
      "Iter: 156 loss: 0.099086191589221467\n",
      "Iter: 157 loss: 0.099086107143529889\n",
      "Iter: 158 loss: 0.099086057948695141\n",
      "Iter: 159 loss: 0.09908588114207563\n",
      "Iter: 160 loss: 0.09908549262783517\n",
      "Iter: 161 loss: 0.099091425083122783\n",
      "Iter: 162 loss: 0.099085475541972626\n",
      "Iter: 163 loss: 0.099085087013804529\n",
      "Iter: 164 loss: 0.099091335389583771\n",
      "Iter: 165 loss: 0.09908508701373453\n",
      "Iter: 166 loss: 0.099084771793591833\n",
      "Iter: 167 loss: 0.099084571210924371\n",
      "Iter: 168 loss: 0.099084447304319062\n",
      "Iter: 169 loss: 0.099084220537280832\n",
      "Iter: 170 loss: 0.099084190501236277\n",
      "Iter: 171 loss: 0.099083953614150885\n",
      "Iter: 172 loss: 0.09908367508729618\n",
      "Iter: 173 loss: 0.099083644196985871\n",
      "Iter: 174 loss: 0.099083183316723264\n",
      "Iter: 175 loss: 0.099085452509452457\n",
      "Iter: 176 loss: 0.099083104407419423\n",
      "Iter: 177 loss: 0.099082666045398657\n",
      "Iter: 178 loss: 0.099082620895271145\n",
      "Iter: 179 loss: 0.099082281844900907\n",
      "Iter: 180 loss: 0.099081889800169964\n",
      "Iter: 181 loss: 0.099084279507640219\n",
      "Iter: 182 loss: 0.099081841458273784\n",
      "Iter: 183 loss: 0.0990816856048538\n",
      "Iter: 184 loss: 0.0990816361157507\n",
      "Iter: 185 loss: 0.099081471190446677\n",
      "Iter: 186 loss: 0.099081106286973752\n",
      "Iter: 187 loss: 0.099086102146545688\n",
      "Iter: 188 loss: 0.099081087874466789\n",
      "Iter: 189 loss: 0.099080271654671009\n",
      "Iter: 190 loss: 0.099082069716328922\n",
      "Iter: 191 loss: 0.0990799557700426\n",
      "Iter: 192 loss: 0.099079599007878008\n",
      "Iter: 193 loss: 0.099079543640418252\n",
      "Iter: 194 loss: 0.0990792116277576\n",
      "Iter: 195 loss: 0.099078616652563845\n",
      "Iter: 196 loss: 0.099093598453149356\n",
      "Iter: 197 loss: 0.099078616636541744\n",
      "Iter: 198 loss: 0.099077809229481159\n",
      "Iter: 199 loss: 0.099081822551604457\n",
      "Iter: 200 loss: 0.0990776623444447\n",
      "Iter: 201 loss: 0.0990775242394585\n",
      "Iter: 202 loss: 0.099077751765351413\n",
      "Iter: 203 loss: 0.09907746138614347\n",
      "Iter: 204 loss: 0.09907722370730343\n",
      "Iter: 205 loss: 0.099077549568926726\n",
      "Iter: 206 loss: 0.099077102100849329\n",
      "Iter: 207 loss: 0.099076761960997531\n",
      "Iter: 208 loss: 0.099076801451551039\n",
      "Iter: 209 loss: 0.099076513765303312\n",
      "Iter: 210 loss: 0.099076128979735265\n",
      "Iter: 211 loss: 0.099075706943643538\n",
      "Iter: 212 loss: 0.0990756374411695\n",
      "Iter: 213 loss: 0.099075255680954308\n",
      "Iter: 214 loss: 0.099077649963398337\n",
      "Iter: 215 loss: 0.099075213257442771\n",
      "Iter: 216 loss: 0.099075001935771873\n",
      "Iter: 217 loss: 0.099075676123028381\n",
      "Iter: 218 loss: 0.099074941457115512\n",
      "Iter: 219 loss: 0.0990745492658531\n",
      "Iter: 220 loss: 0.0990754082915791\n",
      "Iter: 221 loss: 0.099074393578499315\n",
      "Iter: 222 loss: 0.099073866192074325\n",
      "Iter: 223 loss: 0.099077584133474034\n",
      "Iter: 224 loss: 0.099073822163263311\n",
      "Iter: 225 loss: 0.099073537839412168\n",
      "Iter: 226 loss: 0.099072894042256318\n",
      "Iter: 227 loss: 0.0990818438449872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 228 loss: 0.099072855844499791\n",
      "Iter: 229 loss: 0.099072540049586932\n",
      "Iter: 230 loss: 0.09907648849176906\n",
      "Iter: 231 loss: 0.099072537148842135\n",
      "Iter: 232 loss: 0.099072386012216962\n",
      "Iter: 233 loss: 0.099072928162807189\n",
      "Iter: 234 loss: 0.099072348470383653\n",
      "Iter: 235 loss: 0.099072130793739818\n",
      "Iter: 236 loss: 0.099072557673091616\n",
      "Iter: 237 loss: 0.099072039298773742\n",
      "Iter: 238 loss: 0.099071859324362452\n",
      "Iter: 239 loss: 0.099073696394473026\n",
      "Iter: 240 loss: 0.099071854121661071\n",
      "Iter: 241 loss: 0.099071732554863554\n",
      "Iter: 242 loss: 0.099071608254159685\n",
      "Iter: 243 loss: 0.099071584019041523\n",
      "Iter: 244 loss: 0.09907134799514182\n",
      "Iter: 245 loss: 0.099071517817972882\n",
      "Iter: 246 loss: 0.09907120076726865\n",
      "Iter: 247 loss: 0.099088129960182472\n",
      "Iter: 248 loss: 0.099071110077278951\n",
      "Iter: 249 loss: 0.099071027316916707\n",
      "Iter: 250 loss: 0.09907101312685726\n",
      "Iter: 251 loss: 0.099070955848781839\n",
      "Iter: 252 loss: 0.099070779286278679\n",
      "Iter: 253 loss: 0.099070765826535789\n",
      "Iter: 254 loss: 0.099070634839834665\n",
      "Iter: 255 loss: 0.099070394442295387\n",
      "Iter: 256 loss: 0.099070269610375086\n",
      "Iter: 257 loss: 0.099070101316438841\n",
      "Iter: 258 loss: 0.099070749743357389\n",
      "Iter: 259 loss: 0.099070061772498247\n",
      "Iter: 260 loss: 0.099069980718042724\n",
      "Iter: 261 loss: 0.099069743490514589\n",
      "Iter: 262 loss: 0.0990706556390942\n",
      "Iter: 263 loss: 0.099069642894350177\n",
      "Iter: 264 loss: 0.099069349655221073\n",
      "Iter: 265 loss: 0.09907034091747699\n",
      "Iter: 266 loss: 0.09906926780315789\n",
      "Iter: 267 loss: 0.099069171589319785\n",
      "Iter: 268 loss: 0.099069060884202781\n",
      "Iter: 269 loss: 0.0990688803109451\n",
      "Iter: 270 loss: 0.099068626579126809\n",
      "Iter: 271 loss: 0.09906861692547024\n",
      "Iter: 272 loss: 0.099068675894463609\n",
      "Iter: 273 loss: 0.09906851185935503\n",
      "Iter: 274 loss: 0.09906844686362036\n",
      "Iter: 275 loss: 0.099068448136048717\n",
      "Iter: 276 loss: 0.0990683942514175\n",
      "Iter: 277 loss: 0.099068454830631175\n",
      "Iter: 278 loss: 0.099068319208914263\n",
      "Iter: 279 loss: 0.09906817378908564\n",
      "Iter: 280 loss: 0.099068425180210737\n",
      "Iter: 281 loss: 0.099068109359437273\n",
      "Iter: 282 loss: 0.099068050472348679\n",
      "Iter: 283 loss: 0.099067900235122547\n",
      "Iter: 284 loss: 0.099069185624013012\n",
      "Iter: 285 loss: 0.099067875506957018\n",
      "Iter: 286 loss: 0.099067652830955852\n",
      "Iter: 287 loss: 0.0990679416414947\n",
      "Iter: 288 loss: 0.099067539282973613\n",
      "Iter: 289 loss: 0.09906740430397587\n",
      "Iter: 290 loss: 0.099068876856830593\n",
      "Iter: 291 loss: 0.09906740153064103\n",
      "Iter: 292 loss: 0.099067265002872759\n",
      "Iter: 293 loss: 0.099066970772883789\n",
      "Iter: 294 loss: 0.099071777817333534\n",
      "Iter: 295 loss: 0.099066960620165762\n",
      "Iter: 296 loss: 0.099066152308707189\n",
      "Iter: 297 loss: 0.099064775532256982\n",
      "Iter: 298 loss: 0.099064772445343591\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "func = function_factory(m1, m1.loss_Total, X_u_train,u_train,X_f_train)\n",
    "init_params = tf.dynamic_stitch(func.idx, m1.trainable_variables)\n",
    "\n",
    "## L-BFGS 优化阶段\n",
    "results = tfp.optimizer.lbfgs_minimize(\n",
    "    value_and_gradients_function=func,\n",
    "    initial_position=init_params, \n",
    "    num_correction_pairs=10, \n",
    "    x_tolerance = 0,\n",
    "    f_relative_tolerance = 0,\n",
    "    parallel_iterations = 1,\n",
    "    max_line_search_iterations = 100,\n",
    "    max_iterations=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eMupnZ17zWRi",
   "metadata": {
    "id": "eMupnZ17zWRi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 0.73604\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000001FB86790B20>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2789, in while_loop\n",
      "    return result  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2745, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 655, in compute\n",
      "    return (next_i, flat_a_out, tas)  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 650, in <listcomp>\n",
      "    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_a_out)]  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = m1(X_u_test)\n",
    "\n",
    "error_vec = np.linalg.norm((u-u_pred),2)/np.linalg.norm(u,2)        # Relative L2 Norm of the error (Vector)\n",
    "print('Test Error: %.5f'  % (error_vec))\n",
    "\n",
    "u_pred = np.reshape(u_pred,(256,100),order='F')                        # Fortran Style ,stacked column wise!\n",
    "\n",
    "''' Solution Plot '''\n",
    "solutionplot(u_pred,X_u_train,u_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "myPINN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
