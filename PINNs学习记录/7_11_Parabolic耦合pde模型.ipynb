{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fac3620a",
   "metadata": {},
   "source": [
    "<img src='./Data/公式0.png'>\n",
    "<img src='./Data/公式1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5e2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import*\n",
    "import numpy as np\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298178bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = symbols('x')\n",
    "y = symbols('y')\n",
    "t = symbols('t')\n",
    "\n",
    "a = v1 = v2 = k =1 #a = 4 ,v1=5,v2=10,k=1/4\n",
    "c1 = 1 + v1/k ;c2 = -v1/v2;c3 = c2 - c1\n",
    "g1 = g2 =0\n",
    "\n",
    "u1 = (1-x)*(1-y)*exp(-t)\n",
    "u2 = (1-x)*(c1 + c2*y + c3*y**2)*exp(-t)\n",
    "\n",
    "u1_0 = (1-x)*(1-y)\n",
    "u2_0 = (1-x)*(c1 + c2*y + c3*y**2)\n",
    "\n",
    "f1 = diff(u1,t) - v1*( diff(u1,x,2) + diff(u1,y,2))\n",
    "f2 = diff(u2,t) - v1*( diff(u2,x,2) + diff(u2,y,2))\n",
    "\n",
    "u1 = lambdify((x,y,t),u1)\n",
    "u2 = lambdify((x,y,t),u2)\n",
    "\n",
    "u1_0 = lambdify((x,y),u1_0)\n",
    "u2_0 = lambdify((x,y),u2_0)\n",
    "\n",
    "f1 = lambdify((x,y,t),f1,'tensorflow')\n",
    "f2 = lambdify((x,y,t),f2,'tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecad79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = [0,-1]\n",
    "n2 = [0,1]\n",
    "\n",
    "omga1 = [[0.,1.],[0.,1.]]  # (x,y)的取值范围 \n",
    "omga2 = [[0.,1.],[-1.,0.]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799b9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f,N_i,omga,u,interface):    \n",
    "    \n",
    "    # x1 = x,  x2 = y\n",
    "    # interface = 0, 则x2_range[0] 作为 interface ； interfacer = 1 则 x2_range[1]作为interface\n",
    "    \n",
    "    x1_range = omga[0]\n",
    "    x2_range = omga[1]\n",
    "    t_range = [0.,1.]\n",
    "    \n",
    "    x1 = np.linspace(x1_range[0],x1_range[1],N_u)\n",
    "    x2 = np.linspace(x2_range[0],x2_range[1],N_u)\n",
    "    t = np.linspace(t_range[0],t_range[1],N_u)\n",
    "    \n",
    "    # Initial Condition t=0 , x1_range[0]<= x1 <= x_range[1] , x2_range[0] <= x2 <= x2_range[1]\n",
    "    X1,X2 = np.meshgrid(x1,x2)\n",
    "    initial_X = np.zeros(shape=(N_u**2,3))\n",
    "    initial_u = np.zeros(shape=(N_u**2,1))\n",
    "    for i in range(N_u):\n",
    "        for j in range(N_u):\n",
    "            initial_X[i*N_u+j,:] = [X1[i][j], X2[i][j], t_range[0]]\n",
    "            initial_u[i*N_u+j] = u(X1[i][j],X2[i][j], t_range[0]) \n",
    "            \n",
    "    # BC_left: x1=x1_range[0], 0<=t<=1, x2_range[0] <= x2 <= x2_range[1]\n",
    "    X2,T = np.meshgrid(x2,t)\n",
    "    leftedge_X = np.zeros(shape=(N_u**2,3))\n",
    "    leftedge_u = np.zeros(shape=(N_u**2,1))\n",
    "    for i in range(N_u):\n",
    "        for j in range(N_u):\n",
    "            leftedge_X[i*N_u+j,:] = [x1_range[0], X2[i][j], T[i,j]]\n",
    "            leftedge_u[i*N_u+j] = u(x1_range[0],X2[i][j], T[i,j]) \n",
    "    \n",
    "    # BC_right: x1=x1_range[1], 0<=t<=1, x2_range[0] <= x2 <= x2_range[1]\n",
    "    X2,T = np.meshgrid(x2,t)\n",
    "    rightedge_X = np.zeros(shape=(N_u**2,3))\n",
    "    rightedge_u = np.zeros(shape=(N_u**2,1))\n",
    "    for i in range(N_u):\n",
    "        for j in range(N_u):\n",
    "            rightedge_X[i*N_u+j,:] = [x1_range[1], X2[i][j], T[i,j]]\n",
    "            rightedge_u[i*N_u+j] = u(x1_range[1],X2[i][j], T[i,j]) \n",
    "            \n",
    "    # BC_top or BC_bottom ,depends on interface. x2 = x2_range[bc], 0<=t<=1 ,x1_range[0]<= x1 <= x_range[1]\n",
    "    bc = (interface+1)%2\n",
    "    X1,T = np.meshgrid(x1,t)\n",
    "    BC_X = np.zeros(shape=(N_u**2,3))\n",
    "    BC_u = np.zeros(shape=(N_u**2,1))\n",
    "    for i in range(N_u):\n",
    "        for j in range(N_u):\n",
    "            BC_X[i*N_u+j,:] = [X1[i,j],x2_range[bc], T[i,j]]\n",
    "            BC_u[i*N_u+j] = u(X1[i,j],x2_range[bc], T[i,j]) \n",
    "    \n",
    "    all_X_u_train =  np.vstack([initial_X,leftedge_X,rightedge_X,BC_X])\n",
    "    all_u_train = np.vstack([initial_u,leftedge_u,rightedge_u,BC_u])\n",
    "    \n",
    "    idx = np.random.choice(all_X_u_train.shape[0], N_u, replace=False) \n",
    "    \n",
    "    X_u_train = all_X_u_train[idx,:]\n",
    "    u_train = all_u_train[idx,:]\n",
    "    \n",
    "    # BC_interface: x2 = x2_range[interface], 0<=t<=1 ,x1_range[0]<= x1 <= x_range[1]\n",
    "    x1 = np.linspace(x1_range[0],x1_range[1],N_i)\n",
    "    t = np.linspace(t_range[0],t_range[1],N_i)\n",
    "    X1,T = np.meshgrid(x1,t)\n",
    "    interface_X = np.zeros(shape=(N_i**2,3))\n",
    "    for i in range(N_i):\n",
    "        for j in range(N_i):\n",
    "            interface_X[i*N_i+j,:] = [X1[i,j],x2_range[interface], T[i,j]]\n",
    "            \n",
    "    idx = np.random.choice(interface_X.shape[0], N_i, replace=False) \n",
    "    X_i_train = interface_X[idx,:]        \n",
    "            \n",
    "    '''Collocation Points'''\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x1,x2,t)\n",
    "    lb = np.array([x1_range[0],x2_range[0],t_range[0]])\n",
    "    ub = np.array([x1_range[1],x2_range[1],t_range[1]])\n",
    "    X_f_train = lb + (ub-lb)*lhs(3,N_f) \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "    \n",
    "    \n",
    "    return X_u_train,u_train,X_f_train,X_i_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb08a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_i = 100\n",
    "\n",
    "N_u1 = 100; N_f1 = 1000  ;omga = omga1; interface=0; u = u1\n",
    "X_u1_train,u1_train,X_f1_train,X_i_train= trainingdata(N_u1,N_f1,N_i,omga,u,interface)\n",
    "\n",
    "\n",
    "N_u2 = 100; N_f2= 1000 ; omga = omga2; interface=1; u = u2\n",
    "X_u2_train,u2_train,X_f2_train,X_i_train= trainingdata(N_u2,N_f2,N_i,omga,u,interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7449de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c73f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPinn(keras.Sequential): ## 正在编写\n",
    "    def __init__(self,Layers,v,n,k,f,name = None):\n",
    "        super(MyPinn, self).__init__(name=name)\n",
    "        self.add(keras.Input(shape=(Layers[0],) ,dtype=tf.float64))\n",
    "        for i in range(1,len(Layers)-1):\n",
    "            self.add(keras.layers.Dense(Layers[i], dtype=tf.float64, activation='tanh'))\n",
    "        self.add(keras.layers.Dense(Layers[-1],dtype=tf.float64, name=\"outputs\"))\n",
    "        self.v = tf.constant(v,dtype=tf.float64)\n",
    "        self.n = tf.constant(n,shape=(2,1),dtype=tf.float64)\n",
    "        self.k = tf.constant(k,dtype=tf.float64)\n",
    "        self.f = f\n",
    "        \n",
    "    @tf.function\n",
    "    def loss_U(self,X_u_train,u_train):\n",
    "        u= self(X_u_train)\n",
    "        loss_u = tf.reduce_mean(tf.square(u_train - u))\n",
    "        return loss_u\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def loss_PDE(self,X_f_train):\n",
    "      \n",
    "        x = X_f_train[:,0:1]\n",
    "        y = X_f_train[:,1:2]\n",
    "        t = X_f_train[:,2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch([x,y,t])\n",
    "            X = tf.stack([x[:,0],y[:,0],t[:,0]],axis=1)\n",
    "            u = self(X)  \n",
    "            u_x = tape.gradient(u,x)\n",
    "            u_y = tape.gradient(u,y)\n",
    "        #tf.print(u_x)    \n",
    "        u_t = tape.gradient(u, t)     \n",
    "        u_xx = tape.gradient(u_x, x)\n",
    "        u_yy = tape.gradient(u_y, y)\n",
    "\n",
    "        del tape\n",
    "      \n",
    "        loss_f = u_t - self.v *(u_xx + u_yy) - self.f(x,y,t)\n",
    "        loss_f = tf.reduce_mean(tf.square(loss_f))\n",
    "        return loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8d0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss_I(m1,m2,X_i_train):\n",
    "    x = X_i_train[:,0:1]\n",
    "    y = X_i_train[:,1:2]\n",
    "    t = X_i_train[:,2:3]\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([x,y,t])\n",
    "        X = tf.stack([x[:,0],y[:,0],t[:,0]],axis=1)\n",
    "        u1 = m1(X)\n",
    "        u2 = m2(X)\n",
    "    \n",
    "    u1_x = tape.gradient(u1, x)\n",
    "    u1_y = tape.gradient(u1, y)\n",
    "    u2_x = tape.gradient(u2, x)\n",
    "    u2_y = tape.gradient(u2, y)\n",
    "\n",
    "    del tape\n",
    "    \n",
    "    loss_u1 = -m1.v * ( u1_x*m1.n[0] + u1_y*m1.n[1]) - m1.k * (u1-u2)\n",
    "    loss_u2 = -m2.v * ( u2_x*m2.n[0] + u2_y*m2.n[1]) - m2.k * (u2-u1)\n",
    "    #tf.print(loss_u1.shape)\n",
    "    loss_i = tf.concat([loss_u1,loss_u2],axis=1)\n",
    "    #tf.print(loss_I.shape)\n",
    "    loss_i = tf.reduce_mean(tf.square(loss_i))\n",
    "    \n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b571c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(m1,m2,X_u1_train,u1_train,X_f1_train,X_u2_train,u2_train,X_f2_train,X_i_train):\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        loss_m1 = m1.loss_U(X_u1_train,u1_train) + m1.loss_PDE(X_f1_train)\n",
    "        loss_m2 = m2.loss_U(X_u2_train,u2_train) + m2.loss_PDE(X_f2_train)\n",
    "        loss_i = loss_I(m1,m2,X_i_train)\n",
    "        loss = loss_m1 + loss_m2 + loss_i\n",
    "        \n",
    "    gradients_m1 = tape.gradient(loss,m1.trainable_variables)\n",
    "    gradients_m2 = tape.gradient(loss,m2.trainable_variables)\n",
    "    \n",
    "    del tape\n",
    "    \n",
    "    m1.optimizer.apply_gradients(zip(gradients_m1, m1.trainable_variables))\n",
    "    m2.optimizer.apply_gradients(zip(gradients_m2, m2.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def ds_train_n_batch(X_u1_train,u1_train,X_f1_train,X_u2_train,u2_train,X_f2_train,X_i_train,n = 5):\n",
    "    batch_u1 = int(len(X_u1_train)/n) # = int(len(u1_train)/n)\n",
    "    batch_f1 = int(len(X_f1_train)/n)\n",
    "    batch_u2 = int(len(X_u2_train)/n) # = int(len(u2_train)/n)\n",
    "    batch_f2 = int(len(X_f2_train)/n)\n",
    "    batch_i = int(len(X_i_train)/n)\n",
    "    \n",
    "    ds_u1 = tf.data.Dataset.from_tensor_slices( ((X_u1_train,u1_train)) ).batch( batch_u1 )\n",
    "    ds_f1 = tf.data.Dataset.from_tensor_slices( X_f1_train ).batch( batch_f1 )\n",
    "    \n",
    "    ds_u2 = tf.data.Dataset.from_tensor_slices( ((X_u2_train,u2_train)) ).batch( batch_u2 )\n",
    "    ds_f2 = tf.data.Dataset.from_tensor_slices( X_f2_train ).batch( batch_f2 )\n",
    "    \n",
    "    ds_i = tf.data.Dataset.from_tensor_slices(X_i_train).batch(batch_i)\n",
    "\n",
    "    ds = tf.data.Dataset.zip((ds_u1,ds_f1,ds_u2,ds_f2,ds_i))\n",
    "    return ds\n",
    "\n",
    "\n",
    "def train_model(m1,m2,ds,epochs = 100):\n",
    "    for epoch in tf.range(1,epochs+1):\n",
    "            for (x_u1,u1),x_f1,(x_u2,u2),x_f2,x_i in ds:\n",
    "                loss = train_step(m1,m2,x_u1,u1,x_f1,x_u2,u2,x_f2,x_i)\n",
    "            if epoch % 50 == 0:                \n",
    "                tf.print(\n",
    "                  \"Training loss (for per 50 epoches) at epoch \",epoch,\":\",loss\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e46f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers=[3,10,10,1]\n",
    "model_1 = MyPinn(Layers,v1,n1,k,f1,name=\"model_1\")\n",
    "model_1.compile(keras.optimizers.Adam())\n",
    "model_2 = MyPinn(Layers,v2,n2,k,f2,name=\"model_2\")\n",
    "model_2.compile(keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d3a630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Training loss (for per 50 epoches) at epoch  50 : 0.55610351317497841\n",
      "Training loss (for per 50 epoches) at epoch  100 : 0.2898762352437767\n"
     ]
    }
   ],
   "source": [
    "ds = ds_train_n_batch(X_u1_train,u1_train,X_f1_train,X_u2_train,u2_train,X_f2_train,X_i_train,n = 5)\n",
    "\n",
    "train_model(model_1,model_2,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f5815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error For u1 (train by batch ): 0.22123\n"
     ]
    }
   ],
   "source": [
    "xx = tf.linspace(omga1[0][0],omga1[0][1],100)\n",
    "yy = tf.linspace(omga1[1][0],omga1[1][1],100)\n",
    "X,Y = tf.meshgrid(xx,yy)\n",
    "X = tf.reshape(X,[-1])\n",
    "Y = tf.reshape(X,[-1])\n",
    "T = tf.ones(shape=(X.shape[0],))\n",
    "\n",
    "u1_test = u1(X,Y,T).numpy()\n",
    "X_u1_test = tf.stack([X,Y,T])\n",
    "X_u1_test = tf.transpose(X_u1_test)\n",
    "u1_pred = model_1(X_u1_test).numpy().flatten()\n",
    "\n",
    "error_u1 = np.linalg.norm((u1_test-u1_pred),2)/np.linalg.norm(u1_test,2)  \n",
    "print('Test Error For u1 (train by batch ): %.5f'  % (error_u1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
