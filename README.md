<!-- #region -->

# 学习PINNs and TensorFlow 


记录每日 TensorFlow 学习 & PINN 模型学习
> 参考教材：**《30天吃掉那只TensorFlow2》** https://github.com/lyhue1991/eat_tensorflow2_in_30_days



| 日期            | 学习内容                                                     | 备注                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **7.15**        | 改进parabolic耦合pde的代码。                                 | ①耦合训练5000次，loss不怎么下降 ②两个区域分布进行单独的PINN训练 训练准确度提升 |
| **7.12**        | 更新PINN学习记录。 训练模型parabolic模型，通过图像，将真实解和PINN模型解做对比。 | u1拟合地很好，u2在多次训练后效果仍然很差。 可能是因为u2中含有y的二次项，而u1中只有y的一次项。 也可能是代码细节出错，正在研究。。。 |
| 7.13            | 与2位学长会议交流，讨论PINN                                  | 解决了不少疑问，PINN在边界处的拟合效果确实一般。             |
| **7.11**        | 更新PINN学习记录。**使用PINN求解parabolic耦合pde模型**       | 代码见 **7_11_Parabolic耦合pde模型.ipynb** 画图部分还没写，训练数据的生成代码，写的有些冗长，后面会优化一下。 |
| 7.8             | 阅读一篇论文，关于pde耦合模型的数值求解方法。 尝试小批量训练模型，即把训练数据分组，规模减少，但训练次数相应会上升。 |                                                              |
| **7.7**         | 阅读张学长的论文：PINN求解naiver-stokes/Darcy耦合模型的正反问题 | 简单来说，Inputs连接两个独立的NN，分别预测U_{ns} 和 U_{d}， 构造naiver-stokes方程组和Darcy方程组的各自微分方程残差项， 以及interface处的残差项，最后加到一起，形成loss。 |
| **7.6**         | 今天阅读学习了一些NN在PDE求解问题中的多种方法。              |                                                              |
| **7.5**         | 更新PINN学习记录，Debug完成，**代码框架搭建告一段落！**。 后续开始阅读PINN相关论文。 | Debug比写代码要费时间，有一个小错误，看了2个小时硬是没看出来 让我一度以为，搭建思路不行，需要重新搭，或者抄别人。 还有一个“错误”，仅仅仅仅是写法不同，却能导致训练失败。 具体分析在: PINNs学习记录/PINNs.md |
| **7.4**         | 更新PINN学习记录，Data Prep & Plot 代码，调试模型进行训练    | 使用Google colab进行云计算，白嫖算力😍 模型训练没有达到预期，正在debug |
| **7.1**         | 更新PINN学习记录，讨论优化器Adam&L-BFGS，写优化器的代码      | Adam优化器调用起来很简单。 而L-BFGS 需要安装tfp，需要一些复杂的操作才能使用🤣。 |
| **6.30**        | 更新PINN学习记录，完成PINN框架代码搭建。 以**Burgers_Equation**为例，模型训练运行成功，之后将完善细节。 | 今天大概写了一天代码，看了很多官方文档， 本来想调用高阶API训练模型，发现自带的高阶API局限性太强 不如自己重新定义训练过程😢 |
| **6.29**        | 更新PINN学习记录、阅读TensorFlow官方文档                     |                                                              |
| **6.28**        | 11_Loss&Regularizer                                          | 常用损失函数 & 自定义loss & 正则化器                         |
| **6.27**        | 10_tf.layers                                                 | 若干模型层 & 自定义模型层                                    |
| **6.25 - 6.26** | 8_tf.data 数据管道 + 9_tf.Activations 激活函数               | NULL                                                         |
| **~6.25**       | 1_Graph ~ 7_Module                                           | NULL                                                         |



<!-- #endregion -->
